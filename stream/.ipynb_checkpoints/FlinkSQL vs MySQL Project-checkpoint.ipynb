{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "678bb5c3",
   "metadata": {},
   "source": [
    "# FlinkSQL vs MySQL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2770f6",
   "metadata": {},
   "source": [
    "Implement the following FlinkSQL query using mysql and python. The goal is emulating FlinkSQL behavior as close as possible. You need to test different ingestion rates and batching strategy for the ingestion, and focus on the implementation of the reporting.\n",
    "\n",
    "-  you can tune the ingestion rate\n",
    "-  you can implement the window semantics in the where clause or by micro batching\n",
    "-  you can use triggers or any SQL construct that you know\n",
    "-  you can assume that processing time and event time coincide\n",
    "-  you can create as many supporting structure \n",
    "-  DON'T FORGET TO REMOVE OLD DATA (USING ANOTHER THREAD?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2bb86b",
   "metadata": {},
   "source": [
    "## FLINK SQL Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63098644",
   "metadata": {},
   "source": [
    "You can run the FlinkSQL query below by ssh to the sql-client container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6ee6e2",
   "metadata": {},
   "source": [
    "```docker exec -it stream_sql-client_1 ./sql-client.sh```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb2e66f",
   "metadata": {},
   "source": [
    "```sql \n",
    "SELECT \n",
    "TUMBLE_START(ts, INTERVAL '1' MINUTE) AS openW, \n",
    "TUMBLE_END(ts, INTERVAL '1' MINUTE) AS closeW, \n",
    "country, \n",
    "COUNT(*) AS cnt \n",
    "FROM Clicks \n",
    "GROUP BY country, TUMBLE(ts, INTERVAL '1' MINUTE);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6e195c",
   "metadata": {},
   "source": [
    "<img src=\"flinkout.png\" alt=\"5\" border=\"0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e38739",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11e502f",
   "metadata": {},
   "source": [
    "For the ingestion, Flink will read directly from Apache Kafka topic ```clicks```. On the other hand, MySQL ingestion will make use of an SQL query.\n",
    "\n",
    "Before getting started, enure that the following python libraries are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b3581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install mysql-connector-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014efd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install confluent_kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5ee3d2",
   "metadata": {},
   "source": [
    "## Kafka Ingestion for Flink"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3a029b",
   "metadata": {},
   "source": [
    "This producer is relevant for Apache Flink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d81be8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "import sys, json\n",
    "topic = \"clicks\"\n",
    "brokers = \"kafka:9092\" # Brokers act as cluster entripoints\n",
    "conf = {'bootstrap.servers': brokers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "234b6d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Producer(**conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "db83e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delivery_callback(err, msg):\n",
    "        if err:\n",
    "            sys.stderr.write('%% Message failed delivery: %s\\n' % err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49126e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def to_kafka(ms):\n",
    "    for m in ms:\n",
    "        k = {}\n",
    "        k['user']=m[0]\n",
    "        k['country']=m[1]\n",
    "        k['eventTime']=datetime.utcfromtimestamp(m[2]).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        p.produce(topic, json.dumps(k), callback=delivery_callback)\n",
    "    p.poll(0)\n",
    "    p.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71675542",
   "metadata": {},
   "source": [
    "## MySQL ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f16e477",
   "metadata": {},
   "source": [
    "The code below sets up the ingestion in MySQL.\n",
    "\n",
    "A database named stream is created and will be used for the querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "471fa2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"mysql\",\n",
    "  user=\"root\",\n",
    "  password=\"pass1234\"\n",
    ")\n",
    "\n",
    "\n",
    "mycursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb4530ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "1007 (HY000): Can't create database 'stream'; database exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMySQLInterfaceError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/mysql/connector/connection_cext.py\u001b[0m in \u001b[0;36mcmd_query\u001b[0;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m             self._cmysql.query(query,\n\u001b[0m\u001b[1;32m    507\u001b[0m                                \u001b[0mraw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffered\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMySQLInterfaceError\u001b[0m: Can't create database 'stream'; database exists",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-31318eaa264b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmycursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CREATE DATABASE stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/mysql/connector/cursor_cext.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, operation, params, multi)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             result = self._cnx.cmd_query(stmt, raw=self._raw,\n\u001b[0m\u001b[1;32m    270\u001b[0m                                          \u001b[0mbuffered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffered\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                                          raw_as_string=self._raw_as_string)\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/mysql/connector/connection_cext.py\u001b[0m in \u001b[0;36mcmd_query\u001b[0;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[1;32m    508\u001b[0m                                raw_as_string=raw_as_string)\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMySQLInterfaceError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m             raise errors.get_mysql_exception(exc.errno, msg=exc.msg,\n\u001b[0m\u001b[1;32m    511\u001b[0m                                              sqlstate=exc.sqlstate)\n\u001b[1;32m    512\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: 1007 (HY000): Can't create database 'stream'; database exists"
     ]
    }
   ],
   "source": [
    "mycursor.execute(\"CREATE DATABASE stream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "46c2460e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('db',)\n",
      "('information_schema',)\n",
      "('mysql',)\n",
      "('performance_schema',)\n",
      "('stream',)\n",
      "('sys',)\n"
     ]
    }
   ],
   "source": [
    "mycursor.execute(\"SHOW DATABASES\")\n",
    "for x in mycursor:\n",
    "  print(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "60297368",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"USE stream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2bd0dc7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "1050 (42S01): Table 'clicks' already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMySQLInterfaceError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/mysql/connector/connection_cext.py\u001b[0m in \u001b[0;36mcmd_query\u001b[0;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m             self._cmysql.query(query,\n\u001b[0m\u001b[1;32m    507\u001b[0m                                \u001b[0mraw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffered\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMySQLInterfaceError\u001b[0m: Table 'clicks' already exists",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-e6b090f3a59e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmycursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CREATE TABLE clicks (user VARCHAR(255), country VARCHAR(255), timestamp INT)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmycursor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/mysql/connector/cursor_cext.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, operation, params, multi)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             result = self._cnx.cmd_query(stmt, raw=self._raw,\n\u001b[0m\u001b[1;32m    270\u001b[0m                                          \u001b[0mbuffered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffered\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                                          raw_as_string=self._raw_as_string)\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/mysql/connector/connection_cext.py\u001b[0m in \u001b[0;36mcmd_query\u001b[0;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[1;32m    508\u001b[0m                                raw_as_string=raw_as_string)\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMySQLInterfaceError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m             raise errors.get_mysql_exception(exc.errno, msg=exc.msg,\n\u001b[0m\u001b[1;32m    511\u001b[0m                                              sqlstate=exc.sqlstate)\n\u001b[1;32m    512\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: 1050 (42S01): Table 'clicks' already exists"
     ]
    }
   ],
   "source": [
    "mycursor.execute(\"CREATE TABLE clicks (user VARCHAR(255), country VARCHAR(255), timestamp INT)\")\n",
    "for x in mycursor:\n",
    "  print(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1dde81ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"INSERT INTO clicks (user, country, timestamp) VALUES (%s, %s, %s)\"\n",
    "def to_my_sql(val):\n",
    "    mycursor.executemany(sql, val)\n",
    "    mydb.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30169c1",
   "metadata": {},
   "source": [
    "## Data Generator\n",
    "The data generator here sends data to mysql and a kafka topic for Flink testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e9877828",
   "metadata": {},
   "outputs": [],
   "source": [
    "userNames = [\"Andy\", \"Bob\", \"Carl\", \"Dave\", \"Esther\", \"Fanny\", \"Gabe\", \"Imogen\", \"John\", \"Louis\", \"Monica\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ca9d7242",
   "metadata": {},
   "outputs": [],
   "source": [
    "regionNames = [\"America\", \"Europe\", \"Asia\", \"Australia\", \"Africa\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "510c69e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a728803",
   "metadata": {},
   "source": [
    "## These are the parameter to control in order to test the ingestion rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2a5fa655",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_window= 60 # seconds\n",
    "batches_per_window= 1000\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e90ec9",
   "metadata": {},
   "source": [
    "The datagen below automatically ingest in Kafka and MySQL using the functions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45481a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    for i in range(0,batches_per_window):\n",
    "        val = []\n",
    "        for i in range(0,batch_size):\n",
    "            ts = int(time.time())\n",
    "            val.append((random.sample(userNames, 1)[0],random.sample(regionNames, 1)[0], ts))\n",
    "        to_my_sql(val) # Send the data to mysql\n",
    "        to_kafka(val) # Send the data to Flink via Kafka\n",
    "    time.sleep(batch_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794db017",
   "metadata": {},
   "source": [
    "# COPY THIS NOTEBOOK TO CONTINUE INGESTING IN PARALLEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372b58fa",
   "metadata": {},
   "source": [
    "<img src=\"copy.png\" alt=\"5\" border=\"0\" width='500pt'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c87925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"mysql\",\n",
    "  user=\"root\",\n",
    "  password=\"pass1234\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "mycursor.execute(\"USE stream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b22fd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"SELECT * FROM clicks LIMIT 10\")\n",
    "for x in mycursor:\n",
    "  print(x) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
